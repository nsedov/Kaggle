{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "67fbf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torchvision\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import pickle\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb3409",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3dfcc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9aa5abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DataLoader that scales picture and turns it into torch tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if (self.mode != 'test'):\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        if (self.mode == 'train'):\n",
    "            transform = transforms.Compose([\n",
    "#                 transforms.ToPILImage(),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x / 255, dtype='float32')\n",
    "        x = transform(x)\n",
    "        if (self.mode == 'test'):\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6944e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('train/simpsons_dataset')\n",
    "TEST_DIR = Path('testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7cd25475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.2, \\\n",
    "                                          stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2fc11b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SimpsonsDataset(val_files, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e96e4e",
   "metadata": {},
   "source": [
    "## Basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d20a0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer, scheduler):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        # formal part\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        # batch step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        # history \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "    \n",
    "    scheduler.step()          \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e718e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        # formal part\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        # prediction \n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "        # history \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "184b2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_files, val_files, model, epochs, batch_size, \n",
    "          scheduler, optimizer, criterion):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "    \n",
    "    best_score = 0\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        for epoch in range(epochs):\n",
    "            # train\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion,\\\n",
    "                                              optimizer, scheduler)\n",
    "            print(\"loss\", train_loss)\n",
    "            # validation\n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "            # save best\n",
    "            if (epoch > 15 and val_acc > best_score + 0.003):\n",
    "                torch.save(model, 'ft_model.pt')\n",
    "            # info output \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1f4da8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dbb47",
   "metadata": {},
   "source": [
    "## Model extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1a1a3487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Nikita/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "#model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b6f66a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child number  0\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Child number  1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Child number  2\n",
      "ReLU(inplace=True)\n",
      "Child number  3\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Child number  4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Child number  5\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Child number  6\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Child number  7\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Child number  8\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Child number  9\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for child in model.children():\n",
    "    print('Child number ', i)\n",
    "    print(child)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d13f4e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003af2d1",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c4df408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(train_val_labels))\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dd0daff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_counter = 0\n",
    "for child in model.children():\n",
    "    if child_counter <= 6:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    child_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c87126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "#layers_to_unfreeze = 14\n",
    "\n",
    "# for param in model.features[:-layers_to_unfreeze].parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a883e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will classify :42\n"
     ]
    }
   ],
   "source": [
    "mdl = model.to(DEVICE) \n",
    "print(\"we will classify :{}\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b51e9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_dataset is None:\n",
    "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "    \n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587892d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b1bf9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr, decay_step, lr_decay = 0.005, 3, 0.7\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = initial_lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = decay_step, gamma=lr_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e7b4b686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch:   0%|                                                                                    | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.7799402399269547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   4%|██▉                                                                      | 1/25 [04:22<1:44:49, 262.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 0.7799     val_loss 0.1791 train_acc 0.7919 val_acc 0.9524\n",
      "loss 0.20659407920705736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   8%|█████▊                                                                   | 2/25 [08:39<1:39:30, 259.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: 0.2066     val_loss 0.1704 train_acc 0.9432 val_acc 0.9576\n",
      "loss 0.10699066544932667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  12%|████████▊                                                                | 3/25 [13:00<1:35:19, 259.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: 0.1070     val_loss 0.2052 train_acc 0.9706 val_acc 0.9499\n",
      "loss 0.041333817914238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  16%|███████████▋                                                             | 4/25 [17:21<1:31:05, 260.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 004 train_loss: 0.0413     val_loss 0.1572 train_acc 0.9893 val_acc 0.9611\n",
      "loss 0.04105842212458081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|██████████████▌                                                          | 5/25 [21:41<1:26:44, 260.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 0.0411     val_loss 0.1042 train_acc 0.9888 val_acc 0.9758\n",
      "loss 0.033518871416586285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  24%|█████████████████▌                                                       | 6/25 [26:00<1:22:19, 259.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 006 train_loss: 0.0335     val_loss 0.1236 train_acc 0.9903 val_acc 0.9735\n",
      "loss 0.011187339556696412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  28%|████████████████████▍                                                    | 7/25 [30:21<1:18:05, 260.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 007 train_loss: 0.0112     val_loss 0.1007 train_acc 0.9971 val_acc 0.9804\n",
      "loss 0.014228136434962709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  32%|███████████████████████▎                                                 | 8/25 [34:42<1:13:47, 260.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 008 train_loss: 0.0142     val_loss 0.1143 train_acc 0.9965 val_acc 0.9749\n",
      "loss 0.012865158690830106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  36%|██████████████████████████▎                                              | 9/25 [39:02<1:09:27, 260.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 train_loss: 0.0129     val_loss 0.1249 train_acc 0.9968 val_acc 0.9725\n",
      "loss 0.0045815250073052835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████████████████████████████▊                                           | 10/25 [43:24<1:05:10, 260.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 010 train_loss: 0.0046     val_loss 0.1055 train_acc 0.9990 val_acc 0.9794\n",
      "loss 0.007674494738369834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  44%|███████████████████████████████▋                                        | 11/25 [47:45<1:00:53, 260.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 011 train_loss: 0.0077     val_loss 0.0886 train_acc 0.9977 val_acc 0.9833\n",
      "loss 0.0030495989086240884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  48%|███████████████████████████████████▌                                      | 12/25 [52:07<56:34, 261.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 012 train_loss: 0.0030     val_loss 0.0888 train_acc 0.9993 val_acc 0.9833\n",
      "loss 0.0014440369958564844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  52%|██████████████████████████████████████▍                                   | 13/25 [56:28<52:12, 261.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 013 train_loss: 0.0014     val_loss 0.0784 train_acc 0.9995 val_acc 0.9874\n",
      "loss 0.0006796014579386716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  56%|████████████████████████████████████████▎                               | 14/25 [1:00:49<47:52, 261.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 014 train_loss: 0.0007     val_loss 0.1224 train_acc 0.9999 val_acc 0.9772\n",
      "loss 0.0068922044510238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  60%|███████████████████████████████████████████▏                            | 15/25 [1:05:12<43:36, 261.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 015 train_loss: 0.0069     val_loss 0.1089 train_acc 0.9984 val_acc 0.9827\n",
      "loss 0.001817061489954653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  64%|██████████████████████████████████████████████                          | 16/25 [1:09:34<39:15, 261.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 016 train_loss: 0.0018     val_loss 0.0977 train_acc 0.9996 val_acc 0.9843\n",
      "loss 0.00047145891834487666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  68%|████████████████████████████████████████████████▉                       | 17/25 [1:13:56<34:55, 261.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 017 train_loss: 0.0005     val_loss 0.0823 train_acc 0.9999 val_acc 0.9878\n",
      "loss 0.000167136936591451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  72%|███████████████████████████████████████████████████▊                    | 18/25 [1:18:18<30:32, 261.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 018 train_loss: 0.0002     val_loss 0.0825 train_acc 0.9999 val_acc 0.9879\n",
      "loss 0.00010034776922830888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  76%|██████████████████████████████████████████████████████▋                 | 19/25 [1:22:39<26:10, 261.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 019 train_loss: 0.0001     val_loss 0.0828 train_acc 1.0000 val_acc 0.9881\n",
      "loss 9.289329395865811e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  80%|█████████████████████████████████████████████████████████▌              | 20/25 [1:27:01<21:48, 261.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 020 train_loss: 0.0001     val_loss 0.0888 train_acc 1.0000 val_acc 0.9882\n",
      "loss 0.0001658842882794148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  84%|████████████████████████████████████████████████████████████▍           | 21/25 [1:31:23<17:27, 261.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 021 train_loss: 0.0002     val_loss 0.0873 train_acc 0.9999 val_acc 0.9888\n",
      "loss 0.00012518540991192137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  88%|███████████████████████████████████████████████████████████████▎        | 22/25 [1:35:45<13:05, 261.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 022 train_loss: 0.0001     val_loss 0.0890 train_acc 1.0000 val_acc 0.9881\n",
      "loss 0.0001250132739639361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  92%|██████████████████████████████████████████████████████████████████▏     | 23/25 [1:40:07<08:44, 262.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 023 train_loss: 0.0001     val_loss 0.0884 train_acc 0.9999 val_acc 0.9883\n",
      "loss 0.00010071530534153339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  96%|█████████████████████████████████████████████████████████████████████   | 24/25 [1:44:33<04:23, 263.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 024 train_loss: 0.0001     val_loss 0.0906 train_acc 0.9999 val_acc 0.9883\n",
      "loss 6.876193609166668e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|████████████████████████████████████████████████████████████████████████| 25/25 [1:49:08<00:00, 261.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 025 train_loss: 0.0001     val_loss 0.0918 train_acc 1.0000 val_acc 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(train_dataset, val_dataset, model=mdl, epochs=25, batch_size=32, \\\n",
    "                scheduler = scheduler , optimizer = optimizer, criterion=criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8caa3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history)\n",
    "val_acc = (torch.stack(val_acc)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6e256d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(acc, label=\"train_acc\")\n",
    "plt.plot(val_acc, label=\"val_acc\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72170fb0",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2217bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('ft_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7cb7a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "79f65ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "22db671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(mdl, test_loader)\n",
    "\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f7c586ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from natsort import index_natsorted\n",
    "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "my_submit.sort_values(\n",
    "   by=\"Id\",\n",
    "   key=lambda x: np.argsort(index_natsorted(my_submit[\"Id\"]))\n",
    ")\n",
    "my_submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
